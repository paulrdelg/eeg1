{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdfbdb28-4f9a-43f9-a016-244e9526806e",
   "metadata": {},
   "source": [
    "## Project Final for ECE 556: AI for Radar and Remote Sensing\n",
    "Paul Delgado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f93738a-788b-4ee5-981c-089909ffc29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import csv\n",
    "import os\n",
    "import pathlib\n",
    "import requests\n",
    "import sys\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1d1318-00d2-44ec-8268-add786851e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party packages\n",
    "import mne_bids\n",
    "import openneuro\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035c469f-3fb4-4e06-a586-30bb6ed59dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9832a0ee-4d79-44bc-9742-e16d06a03507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import caffe\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "45bfe0d7-2ebb-46f1-befb-d6a6d4c08ad1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'caffe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [171]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m1\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124micnn\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01micnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01micnn_dgn_gd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reconstruct_image\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01micnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clip_extreme_value, normalise_img\n",
      "File \u001b[1;32m~\\source\\repos\\icnn\\icnn\\icnn_dgn_gd.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msio\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcaffe\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m switch_loss_fun\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_feature_masks, img_deprocess, normalise_img, sort_layer_list\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'caffe'"
     ]
    }
   ],
   "source": [
    "sys.path.insert(1, os.path.normpath(os.path.join(os.getcwd(), '..', 'icnn')))\n",
    "from icnn.icnn_dgn_gd import reconstruct_image\n",
    "from icnn.utils import clip_extreme_value, normalise_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91d39aa-59e4-497e-a6e3-34abf9a33333",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c84f625d-fdfb-4eed-886c-f3bf48a53628",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ds001506'\n",
    "subject = '01'\n",
    "session = 'perceptionNaturalImageTraining01'\n",
    "run = 1\n",
    "#task = 'trance'\n",
    "#suffix = 'inplane'\n",
    "datatype = 'anat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e66f83c-c828-4a5b-a7eb-5ad276c38e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PaulDRP\\source\\repos\\ds001506\n"
     ]
    }
   ],
   "source": [
    "bids_root = os.path.normpath(os.path.join(os.getcwd(), '..', dataset))\n",
    "print(bids_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba966d43-4873-48e0-bc7d-e32c8b254c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(bids_root):\n",
    "    os.makedirs(bids_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d08ed-3c98-4fb9-a906-d0b5089b57f0",
   "metadata": {},
   "source": [
    "#### 1.1) Download Data (BIDS-standard repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29b3fa46-ad60-4e43-8ce2-6daa4b908718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üëã Hello! This is openneuro-py 2022.1.0. Great to see you! ü§ó\n",
      "\n",
      "   üëâ Please report problems ü§Ø and bugs ü™≤ at\n",
      "      https://github.com/hoechenberger/openneuro-py/issues\n",
      "\n",
      "üåç Preparing to download ds001506 ‚Ä¶\n",
      "üëâ Retrieving up to 617 files (5 concurrent downloads).\n",
      "‚úÖ Finished downloading ds001506.\n",
      "\n",
      "üß† Please enjoy your brains.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Skipping dataset_description.json: already downloaded.: 100%|##########| 740/740 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Skipping README: already downloaded.: 100%|##########| 6.78k/6.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Skipping CHANGES: already downloaded.: 100%|##########| 397/397 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#openneuro.download(dataset=dataset, target_dir=bids_root)\n",
    "openneuro.download(dataset=dataset, target_dir=bids_root, include=[f'sub-{subject}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269cde46-58e7-4a2f-88ca-c300922960ca",
   "metadata": {},
   "source": [
    "#### 1.2) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "43f303c8-b627-4235-8d76-7a17e30c24a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/PaulDRP/source/repos/ds001506/sub-01/ses-perceptionNaturalImageTraining01/anat/sub-01_ses-perceptionNaturalImageTraining01\n"
     ]
    }
   ],
   "source": [
    "#bids_path = mne_bids.BIDSPath(root=bids_root, subject=subject, session=session, datatype=datatype, task=task, suffix=suffix, extension='.set')\n",
    "bids_path = mne_bids.BIDSPath(root=bids_root, subject=subject, session=session, datatype=datatype)\n",
    "print(bids_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0d434ed2-5d83-4aa5-aaec-0a9371504227",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Suffix anat is not allowed. Use one of these suffixes ['meg', 'markers', 'eeg', 'ieeg', 'T1w', 'FLASH', 'participants', 'scans', 'electrodes', 'optodes', 'channels', 'coordsystem', 'events', 'headshape', 'digitizer', 'beh', 'physio', 'stim', 'nirs'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43mmne_bids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_raw_bids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbids_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbids_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<decorator-gen-579>:12\u001b[0m, in \u001b[0;36mread_raw_bids\u001b[1;34m(bids_path, extra_params, verbose)\u001b[0m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\mne_bids\\read.py:654\u001b[0m, in \u001b[0;36mread_raw_bids\u001b[1;34m(bids_path, extra_params, verbose)\u001b[0m\n\u001b[0;32m    652\u001b[0m     bids_path\u001b[38;5;241m.\u001b[39mupdate(datatype\u001b[38;5;241m=\u001b[39mdatatype)\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 654\u001b[0m     \u001b[43mbids_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bids_path\u001b[38;5;241m.\u001b[39mfpath\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    657\u001b[0m     bids_raw_folder \u001b[38;5;241m=\u001b[39m bids_path\u001b[38;5;241m.\u001b[39mdirectory \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbids_path\u001b[38;5;241m.\u001b[39mbasename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\mne_bids\\path.py:749\u001b[0m, in \u001b[0;36mBIDSPath.update\u001b[1;34m(self, check, **kwargs)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mold_kwargs)\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck \u001b[38;5;241m=\u001b[39m old_check\n\u001b[1;32m--> 749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\mne_bids\\path.py:743\u001b[0m, in \u001b[0;36mBIDSPath.update\u001b[1;34m(self, check, **kwargs)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;66;03m# Perform a check of the entities and revert changes if check fails\u001b[39;00m\n\u001b[0;32m    742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 743\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    745\u001b[0m     old_check \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\mne_bids\\path.py:867\u001b[0m, in \u001b[0;36mBIDSPath._check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    864\u001b[0m suffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuffix\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    866\u001b[0m         suffix \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ALLOWED_FILENAME_SUFFIX:\n\u001b[1;32m--> 867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuffix \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    868\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse one of these suffixes \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    869\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWED_FILENAME_SUFFIX\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Suffix anat is not allowed. Use one of these suffixes ['meg', 'markers', 'eeg', 'ieeg', 'T1w', 'FLASH', 'participants', 'scans', 'electrodes', 'optodes', 'channels', 'coordsystem', 'events', 'headshape', 'digitizer', 'beh', 'physio', 'stim', 'nirs']."
     ]
    }
   ],
   "source": [
    "raw = mne_bids.read_raw_bids(bids_path=bids_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c814365c-5d49-4814-a0b2-60da00ac00ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mraw\u001b[49m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject_info\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raw' is not defined"
     ]
    }
   ],
   "source": [
    "print(raw.info['subject_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d3730a-ff56-45d0-aefd-e8f3b36f4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.info['sfreq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76fa0c-4ae3-48f8-9c9d-a8507bc0ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0238970-d79e-4f0f-8f56-ade2bf67fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.annotations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1691c5e-0b11-4794-9338-1ebf6897d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.annotations[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a4f2f7-9440-479f-bc88-2c2ddb468088",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.annotations[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a337be54-9aab-4007-a11b-393102522203",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f328977-9792-4e18-857a-870292b3052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_bids.inspect_dataset(bids_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c729ad53-74a7-4745-8612-b1347b4fd7dd",
   "metadata": {},
   "source": [
    "#### 1.3) Format BIDS into Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f169a68-92b4-4a16-b65a-1fedf3e8247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef8534d-0ed9-421b-b80b-54c47270f065",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preloaded Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cbd6219-95b5-45de-8513-4c65b177deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_dir = os.path.normpath(os.path.join(os.getcwd(), '..', 'DeepImageReconstruction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48ae7bb5-2a1c-46e5-b5b6-2ea7b9c70129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU usage settings\n",
    "decoded_features_dir = os.path.normpath(os.path.join(dat_dir, 'data', 'decodedfeatures'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ce5cb1b-4fb8-4cca-a04b-1c04df3ec2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_feature_filename(net, layer, subject, roi, image_type, image_label):\n",
    "    name = '%s-%s-%s-%s-%s-%s.mat' % (image_type, net, layer, subject, roi, image_label)\n",
    "    return os.path.join(decoded_features_dir, image_type, net, layer, subject, roi, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8becf81a-d3b5-469e-819f-ec2fc3c3c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data settings\n",
    "results_dir = os.path.normpath(os.path.join(os.getcwd(), 'results'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b49d9f9a-badd-4ff7-b475-07813aa505c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_list = ['S1', 'S2', 'S3']\n",
    "\n",
    "rois_list = ['VC']\n",
    "\n",
    "network = 'VGG19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0d83f2a-a17a-4cec-bf78-554aa56b378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PaulDRP\\source\\repos\\eeg1\\results\n"
     ]
    }
   ],
   "source": [
    "save_dir_root = results_dir\n",
    "print(save_dir_root)\n",
    "if not os.path.exists(save_dir_root):\n",
    "    os.makedirs(save_dir_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ea2e362-39a2-417b-b92d-0895c5bb112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images in figure 2\n",
    "image_type = 'natural'\n",
    "image_label_list = ['Img0009', 'Img0002', 'Img0001', 'Img0005', 'Img0036', 'Img0045', 'Img0031', 'Img0043']\n",
    "n_iteration = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "113c42a9-a12b-4a88-97a7-733e0d3ceaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average image of ImageNet\n",
    "img_mean_file = os.path.normpath(os.path.join(dat_dir, 'data', 'ilsvrc_2012_mean.npy'))\n",
    "img_mean = np.load(img_mean_file)\n",
    "img_mean = np.float32([img_mean[0].mean(), img_mean[1].mean(), img_mean[2].mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e3522c69-0688-4450-98c4-41db32aba048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "model_file = os.path.normpath(os.path.join(dat_dir, 'net', 'VGG_ILSVRC_19_layers', 'VGG_ILSVRC_19_layers.caffemodel'))\n",
    "prototxt_file = os.path.normpath(os.path.join(dat_dir, 'net', 'VGG_ILSVRC_19_layers', 'VGG_ILSVRC_19_layers.prototxt'))\n",
    "channel_swap = (2, 1, 0)\n",
    "#net = caffe.Classifier(prototxt_file, model_file, mean=img_mean, channel_swap=channel_swap)\n",
    "#h, w = net.blobs['data'].data.shape[-2:]\n",
    "#net.blobs['data'].reshape(1, 3, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28c492b3-455c-4b61-9c5c-9be696fb16f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'caffe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m model_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dat_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator_for_inverting_fc7\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator.caffemodel\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      3\u001b[0m prototxt_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dat_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator_for_inverting_fc7\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator.prototxt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m net_gen \u001b[38;5;241m=\u001b[39m \u001b[43mcaffe\u001b[49m\u001b[38;5;241m.\u001b[39mNet(prototxt_file, model_file, caffe\u001b[38;5;241m.\u001b[39mTEST)\n\u001b[0;32m      5\u001b[0m input_layer_gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeat\u001b[39m\u001b[38;5;124m'\u001b[39m        \u001b[38;5;66;03m# Input layer for generator net\u001b[39;00m\n\u001b[0;32m      6\u001b[0m output_layer_gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'caffe' is not defined"
     ]
    }
   ],
   "source": [
    "# Generator network\n",
    "model_file = os.path.normpath(os.path.join(dat_dir, 'net', 'generator_for_inverting_fc7', 'generator.caffemodel'))\n",
    "prototxt_file = os.path.normpath(os.path.join(dat_dir, 'net', 'generator_for_inverting_fc7', 'generator.prototxt'))\n",
    "net_gen = caffe.Net(prototxt_file, model_file, caffe.TEST)\n",
    "input_layer_gen = 'feat'        # Input layer for generator net\n",
    "output_layer_gen = 'generated'  # Output layer for generator net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcebdadb-4eee-4f31-a730-a357f241d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature size for input layer of the generator net\n",
    "feat_size_gen = net_gen.blobs[input_layer_gen].data.shape[1:]\n",
    "num_of_unit = net_gen.blobs[input_layer_gen].data[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2c773-f298-4f24-ae2f-ef71ea5ac301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper bound for input layer of the generator net\n",
    "bound_file = './data/act_range/3x/fc7.txt'\n",
    "upper_bound = np.loadtxt(bound_file, delimiter=' ', usecols=np.arange(0, num_of_unit), unpack=True)\n",
    "upper_bound = upper_bound.reshape(feat_size_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f147a69-85aa-45e1-9053-fbd48983414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial features for the input layer of the generator (we use a 0 vector as initial features)\n",
    "initial_gen_feat = np.zeros_like(net_gen.blobs[input_layer_gen].data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "da921869-6e80-4b6b-ae4a-99fabd33fbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\estimated_vgg19_cnn_feat_std.mat\n"
     ]
    }
   ],
   "source": [
    "# Feature SD estimated from true CNN features of 10000 images\n",
    "feat_std_file = os.path.normpath(os.path.join(dat_dir, 'data', 'estimated_vgg19_cnn_feat_std.mat'))\n",
    "print(feat_std_file)\n",
    "feat_std0 = sio.loadmat(feat_std_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f61bdafa-50f7-4baf-83ab-da7c097a5f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.input_layer.InputLayer object at 0x00000193E0A4F100>, <keras.layers.convolutional.Conv2D object at 0x00000193E0AC2650>, <keras.layers.convolutional.Conv2D object at 0x00000193E0A5C490>, <keras.layers.pooling.MaxPooling2D object at 0x00000193E0AC2920>, <keras.layers.convolutional.Conv2D object at 0x00000193E0A4F6A0>, <keras.layers.convolutional.Conv2D object at 0x00000193E0B3BA90>, <keras.layers.pooling.MaxPooling2D object at 0x00000193E1170A90>, <keras.layers.convolutional.Conv2D object at 0x00000193E0B3B460>, <keras.layers.convolutional.Conv2D object at 0x00000193E1171EA0>, <keras.layers.convolutional.Conv2D object at 0x00000193E11726B0>, <keras.layers.convolutional.Conv2D object at 0x00000193E1173970>, <keras.layers.pooling.MaxPooling2D object at 0x00000193E1170B20>, <keras.layers.convolutional.Conv2D object at 0x00000193E1172DA0>, <keras.layers.convolutional.Conv2D object at 0x00000193E117DD80>, <keras.layers.convolutional.Conv2D object at 0x00000193E117EAD0>, <keras.layers.convolutional.Conv2D object at 0x00000193E117F580>, <keras.layers.pooling.MaxPooling2D object at 0x00000193E117F9D0>, <keras.layers.convolutional.Conv2D object at 0x00000193E117F880>, <keras.layers.convolutional.Conv2D object at 0x00000193E118C3A0>, <keras.layers.convolutional.Conv2D object at 0x00000193E118E980>, <keras.layers.convolutional.Conv2D object at 0x00000193E118FC40>, <keras.layers.pooling.MaxPooling2D object at 0x00000193E1194940>, <keras.layers.core.flatten.Flatten object at 0x00000193E1194430>, <keras.layers.core.dense.Dense object at 0x00000193E118D360>, <keras.layers.core.dense.Dense object at 0x00000193E1195A20>, <keras.layers.core.dense.Dense object at 0x00000193E1196C20>]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5711be66-283f-40cf-9535-61c13efcf91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0: InputLayer\n",
      "Error finding layer\n",
      "layer 1: block1_conv1 is conv1_1\n",
      "layer 2: block1_conv2 is conv1_2\n",
      "layer 3: block1_pool is pool1\n",
      "layer 4: block2_conv1 is conv2_1\n",
      "layer 5: block2_conv2 is conv2_2\n",
      "layer 6: block2_pool is pool2\n",
      "layer 7: block3_conv1 is conv3_1\n",
      "layer 8: block3_conv2 is conv3_2\n",
      "layer 9: block3_conv3 is conv3_3\n",
      "layer 10: block3_conv4 is conv3_4\n",
      "layer 11: block3_pool is pool3\n",
      "layer 12: block4_conv1 is conv4_1\n",
      "layer 13: block4_conv2 is conv4_2\n",
      "layer 14: block4_conv3 is conv4_3\n",
      "layer 15: block4_conv4 is conv4_4\n",
      "layer 16: block4_pool is pool4\n",
      "layer 17: block5_conv1 is conv5_1\n",
      "layer 18: block5_conv2 is conv5_2\n",
      "layer 19: block5_conv3 is conv5_3\n",
      "layer 20: block5_conv4 is conv5_4\n",
      "layer 21: block5_pool is pool5\n",
      "layer 22: Flatten\n",
      "layer 23: fc1 is fc6\n",
      "layer 24: fc2 is fc7\n",
      "layer 25: predictions is fc8\n"
     ]
    }
   ],
   "source": [
    "# CNN Layers (all conv and fc layers)\n",
    "#layers = [layer for layer in net.blobs.keys() if 'conv' in layer or 'fc' in layer]\n",
    "layers = []\n",
    "\n",
    "#print(tf.keras.layers.Conv2D.__name__)\n",
    "\n",
    "count = 0\n",
    "pool_count = 1\n",
    "block_count = 1\n",
    "for layer in model.layers:\n",
    "    if layer.__class__.__name__ == 'InputLayer':\n",
    "        print(f'layer {count}: InputLayer')\n",
    "        #layers.append('InputLayer')\n",
    "    if layer.__class__.__name__ == 'Conv2D':\n",
    "        sections = layer.name.split('_')\n",
    "        block = sections[0]\n",
    "        blockNum = block[-1]\n",
    "        if int(blockNum) > block_count:\n",
    "            block_count = int(blockNum)\n",
    "        layerNum = sections[1][-1]\n",
    "        val = 'conv' + blockNum + '_' + layerNum\n",
    "        print(f'layer {count}: {layer.name} is {val}')\n",
    "        layers.append(val)\n",
    "    elif layer.__class__.__name__ == 'MaxPooling2D':\n",
    "        sections = layer.name.split('_')\n",
    "        block = sections[0]\n",
    "        blockNum = block[-1]\n",
    "        if int(blockNum) > block_count:\n",
    "            block_count = int(blockNum)\n",
    "        val = 'pool' + blockNum\n",
    "        print(f'layer {count}: {layer.name} is {val}')\n",
    "        layers.append(val)\n",
    "        pool_count = pool_count + 1\n",
    "    elif layer.__class__.__name__ == 'Flatten':\n",
    "        print(f'layer {count}: Flatten')\n",
    "        #layers.append('Flatten')\n",
    "    elif layer.__class__.__name__ == 'Dense':\n",
    "        #print(f'layer {count}: Dense')\n",
    "        block_count = block_count + 1\n",
    "        val = 'fc' + str(block_count)\n",
    "        print(f'layer {count}: {layer.name} is {val}')\n",
    "        layers.append(val)\n",
    "    else:\n",
    "        print('Error finding layer')\n",
    "    count = count + 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "05b857e7-0efa-4da1-837f-ff36e326ac4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'upper_bound' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [172]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set reconstruction options\u001b[39;00m\n\u001b[0;32m      2\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# The loss function type: {'l2','l1','inner','gram'}\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# The total number of iterations for gradient descend\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter_n\u001b[39m\u001b[38;5;124m'\u001b[39m: n_iteration,\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Learning rate\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_start\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2.\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_end\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1e-10\u001b[39m,\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Gradient with momentum\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmomentum_start\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.9\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmomentum_end\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.9\u001b[39m,\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Decay for the features of the input layer of the generator after each\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# iteration\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecay_start\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecay_end\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Name of the input layer of the generator (str)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_layer_gen\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m#input_layer_gen,\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Name of the output layer of the generator (str)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_layer_gen\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# output_layer_gen,\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# Upper and lower boundary for the input layer of the generator\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeat_upper_bound\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mupper_bound\u001b[49m,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeat_lower_bound\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.\u001b[39m,\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# The initial features of the input layer of the generator (setting to\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# None will use random noise as initial features)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitial_gen_feat\u001b[39m\u001b[38;5;124m'\u001b[39m: initial_gen_feat,\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Display the information on the terminal for every n iterations\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp_every\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     38\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'upper_bound' is not defined"
     ]
    }
   ],
   "source": [
    "# Set reconstruction options\n",
    "opts = {\n",
    "    # The loss function type: {'l2','l1','inner','gram'}\n",
    "    'loss_type': 'l2',\n",
    "\n",
    "    # The total number of iterations for gradient descend\n",
    "    'iter_n': n_iteration,\n",
    "\n",
    "    # Learning rate\n",
    "    'lr_start': 2.,\n",
    "    'lr_end': 1e-10,\n",
    "\n",
    "    # Gradient with momentum\n",
    "    'momentum_start': 0.9,\n",
    "    'momentum_end': 0.9,\n",
    "\n",
    "    # Decay for the features of the input layer of the generator after each\n",
    "    # iteration\n",
    "    'decay_start': 0.01,\n",
    "    'decay_end': 0.01,\n",
    "\n",
    "    # Name of the input layer of the generator (str)\n",
    "    'input_layer_gen': 'in1', #input_layer_gen,\n",
    "\n",
    "    # Name of the output layer of the generator (str)\n",
    "    'output_layer_gen': 'out1', # output_layer_gen,\n",
    "\n",
    "    # Upper and lower boundary for the input layer of the generator\n",
    "    'feat_upper_bound': upper_bound,\n",
    "    'feat_lower_bound': 0.,\n",
    "\n",
    "    # The initial features of the input layer of the generator (setting to\n",
    "    # None will use random noise as initial features)\n",
    "    'initial_gen_feat': initial_gen_feat,\n",
    "\n",
    "    # Display the information on the terminal for every n iterations\n",
    "    'disp_every': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b5296552-9ecf-44d1-9ad1-9d85e22e5717",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [162]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save the optional parameters\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir_root, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptions.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 3\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mopts\u001b[49m, f)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'opts' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the optional parameters\n",
    "with open(os.path.join(save_dir_root, 'options.pkl'), 'w') as f:\n",
    "    pickle.dump(opts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "04d3e8dd-7209-4336-a6e4-6d2d58206c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_cnn_feat_std(cnn_feat):\n",
    "    '''\n",
    "    estimate the std of the CNN features\n",
    "\n",
    "    INPUT:\n",
    "        cnn_feat: CNN feature array [channel,dim1,dim2] or [1,channel];\n",
    "\n",
    "    OUTPUT:\n",
    "        cnn_feat_std: std of the CNN feature,\n",
    "        here the std of each channel is estimated first,\n",
    "        then average std across channels;\n",
    "    '''\n",
    "    feat_ndim = cnn_feat.ndim\n",
    "    feat_size = cnn_feat.shape\n",
    "    # for the case of fc layers\n",
    "    if feat_ndim == 1 or (feat_ndim == 2 and feat_size[0] == 1) or (feat_ndim == 3 and feat_size[1] == 1 and feat_size[2] == 1):\n",
    "        cnn_feat_std = np.std(cnn_feat)\n",
    "    # for the case of conv layers\n",
    "    elif feat_ndim == 3 and (feat_size[1] > 1 or feat_size[2] > 1):\n",
    "        num_of_ch = feat_size[0]\n",
    "        # std for each channel\n",
    "        cnn_feat_std = np.zeros(num_of_ch, dtype='float32')\n",
    "        for j in range(num_of_ch):\n",
    "            feat_ch = cnn_feat[j, :, :]\n",
    "            cnn_feat_std[j] = np.std(feat_ch)\n",
    "        cnn_feat_std = np.mean(cnn_feat_std)  # std averaged across channels\n",
    "    return cnn_feat_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1a15eb4b-438a-4638-839d-0de5a2042e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject:     S1\n",
      "ROI:         VC\n",
      "Image label: Img0009\n",
      "\n",
      "save dir: C:\\Users\\PaulDRP\\source\\repos\\eeg1\\results\\S1\\VC\n",
      "loading decoded CNN features\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv1_1\\S1\\VC\\natural-VGG19-conv1_1-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv1_2\\S1\\VC\\natural-VGG19-conv1_2-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\pool1\\S1\\VC\\natural-VGG19-pool1-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv2_1\\S1\\VC\\natural-VGG19-conv2_1-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv2_2\\S1\\VC\\natural-VGG19-conv2_2-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\pool2\\S1\\VC\\natural-VGG19-pool2-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv3_1\\S1\\VC\\natural-VGG19-conv3_1-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv3_2\\S1\\VC\\natural-VGG19-conv3_2-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv3_3\\S1\\VC\\natural-VGG19-conv3_3-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv3_4\\S1\\VC\\natural-VGG19-conv3_4-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\pool3\\S1\\VC\\natural-VGG19-pool3-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv4_1\\S1\\VC\\natural-VGG19-conv4_1-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv4_2\\S1\\VC\\natural-VGG19-conv4_2-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv4_3\\S1\\VC\\natural-VGG19-conv4_3-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv4_4\\S1\\VC\\natural-VGG19-conv4_4-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\pool4\\S1\\VC\\natural-VGG19-pool4-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv5_1\\S1\\VC\\natural-VGG19-conv5_1-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv5_2\\S1\\VC\\natural-VGG19-conv5_2-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv5_3\\S1\\VC\\natural-VGG19-conv5_3-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\conv5_4\\S1\\VC\\natural-VGG19-conv5_4-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\pool5\\S1\\VC\\natural-VGG19-pool5-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\fc6\\S1\\VC\\natural-VGG19-fc6-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\fc7\\S1\\VC\\natural-VGG19-fc7-S1-VC-Img0009.mat\n",
      "C:\\Users\\PaulDRP\\source\\repos\\DeepImageReconstruction\\data\\decodedfeatures\\natural\\VGG19\\fc8\\S1\\VC\\natural-VGG19-fc8-S1-VC-Img0009.mat\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'opts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [170]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m weights \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m/\u001b[39m weights\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     44\u001b[0m layer_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(layers, weights))\n\u001b[1;32m---> 46\u001b[0m \u001b[43mopts\u001b[49m\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: layer_weight})\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Reconstruction\u001b[39;00m\n\u001b[0;32m     49\u001b[0m snapshots_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnapshots\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m image_label)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'opts' is not defined"
     ]
    }
   ],
   "source": [
    "# Reconstrucion\n",
    "\n",
    "for subject, roi, image_label in product(subjects_list, rois_list, image_label_list):\n",
    "\n",
    "    print('')\n",
    "    print('Subject:     ' + subject)\n",
    "    print('ROI:         ' + roi)\n",
    "    print('Image label: ' + image_label)\n",
    "    print('')\n",
    "\n",
    "    save_dir = os.path.join(save_dir_root, subject, roi)\n",
    "    print(f'save dir: {save_dir}')\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Load the decoded CNN features\n",
    "    features = {}\n",
    "    print('loading decoded CNN features')\n",
    "    for layer in layers:\n",
    "        # The file full name depends on the data structure for decoded CNN features\n",
    "        file_name = decode_feature_filename(network, layer, subject, roi, image_type, image_label)\n",
    "        print(file_name)\n",
    "        feat = sio.loadmat(file_name)['feat']\n",
    "        if 'fc' in layer:\n",
    "            feat = feat.reshape(feat.size)\n",
    "\n",
    "        # Correct the norm of the decoded CNN features\n",
    "        feat_std = estimate_cnn_feat_std(feat)\n",
    "        feat = (feat / feat_std) * feat_std0[layer]\n",
    "\n",
    "        features.update({layer: feat})\n",
    "\n",
    "    # Weight of each layer in the total loss function\n",
    "\n",
    "    # Norm of the CNN features for each layer\n",
    "    feat_norm = np.array([np.linalg.norm(features[layer]) for layer in layers], dtype='float32')\n",
    "\n",
    "    # Use the inverse of the squared norm of the CNN features as the weight for each layer\n",
    "    weights = 1. / (feat_norm ** 2)\n",
    "\n",
    "    # Normalise the weights such that the sum of the weights = 1\n",
    "    weights = weights / weights.sum()\n",
    "    layer_weight = dict(zip(layers, weights))\n",
    "\n",
    "    opts.update({'layer_weight': layer_weight})\n",
    "\n",
    "    # Reconstruction\n",
    "    snapshots_dir = os.path.join(save_dir, 'snapshots', 'image-%s' % image_label)\n",
    "    recon_img, loss_list = reconstruct_image(features, net, net_gen,\n",
    "                                             save_intermediate=True,\n",
    "                                             save_intermediate_path=snapshots_dir,\n",
    "                                             **opts)\n",
    "\n",
    "    # Save the results\n",
    "\n",
    "    # Save the raw reconstructed image\n",
    "    save_name = 'recon_img' + '-' + image_label + '.mat'\n",
    "    sio.savemat(os.path.join(save_dir, save_name), {'recon_img': recon_img})\n",
    "\n",
    "    # To better display the image, clip pixels with extreme values (0.02% of\n",
    "    # pixels with extreme low values and 0.02% of the pixels with extreme high\n",
    "    # values). And then normalise the image by mapping the pixel value to be\n",
    "    # within [0,255].\n",
    "    save_name = 'recon_img_normalized' + '-' + image_label + '.jpg'\n",
    "    PIL.Image.fromarray(normalise_img(clip_extreme_value(recon_img, pct=4))).save(os.path.join(save_dir, save_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb03e3-85b4-4bfd-a0cf-016ed11333d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1612aa-8f2a-46d9-951c-316da2035a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c37fb-2dc5-4f9b-88ae-7938f0cec914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f12ec-e9a8-40e8-bfe2-faa4a277a627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1339603-4428-41bf-9ab7-96efbe1b6d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06ee7812-caeb-4718-b8b3-4769af91af29",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea336f00-ac57-4791-b6f7-e6fa5c65f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.vgg19.VGG19()\n",
    "#model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24ad01c8-b519-43d8-b0e6-a6f1006b0de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining04_task-perception_run-03_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining04_task-perception_run-04_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining05_inplaneT2.nii.gz: file size mismatch.: 0.00B [00:00‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining04_task-perception_run-05_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining04_task-perception_run-06_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining04_task-perception_run-07_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining04_task-perception_run-08_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining05_task-perception_run-01_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining05_task-perception_run-02_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining05_task-perception_run-03_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining05_task-perception_run-04_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining05_task-perception_run-05_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining06_inplaneT2.nii.gz: file size mismatch.: 0.00B [00:00‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining05_task-perception_run-06_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining05_task-perception_run-07_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining05_task-perception_run-08_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining06_task-perception_run-01_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining06_task-perception_run-02_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining06_task-perception_run-03_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining06_task-perception_run-04_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining07_inplaneT2.nii.gz: file size mismatch.: 0.00B [00:00‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining06_task-perception_run-05_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining06_task-perception_run-06_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining06_task-perception_run-07_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining06_task-perception_run-08_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining08_inplaneT2.nii.gz: file size mismatch.: 0.00B [00:00‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining07_task-perception_run-01_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining07_task-perception_run-02_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining07_task-perception_run-03_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining07_task-perception_run-04_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining08_task-perception_run-01_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining08_task-perception_run-02_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining08_task-perception_run-04_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining08_task-perception_run-03_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining08_task-perception_run-05_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining08_task-perception_run-06_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining08_task-perception_run-07_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining08_task-perception_run-08_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining08_task-perception_run-09_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining09_inplaneT2.nii.gz: file size mismatch.: 0.00B [00:00‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining08_task-perception_run-10_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining09_task-perception_run-03_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining09_task-perception_run-01_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining09_task-perception_run-04_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining09_task-perception_run-02_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining09_task-perception_run-05_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining09_task-perception_run-06_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining09_task-perception_run-07_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining09_task-perception_run-08_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining09_task-perception_run-09_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining09_task-perception_run-10_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining10_inplaneT2.nii.gz: file size mismatch.: 0.00B [00:00‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining10_task-perception_run-01_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining10_task-perception_run-02_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining10_task-perception_run-03_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining10_task-perception_run-05_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining10_task-perception_run-04_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining11_inplaneT2.nii.gz: file size mismatch.: 0.00B [00:00‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining10_task-perception_run-06_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining10_task-perception_run-07_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining10_task-perception_run-08_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining11_task-perception_run-01_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining11_task-perception_run-02_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining11_task-perception_run-03_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining11_task-perception_run-04_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining11_task-perception_run-05_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining12_inplaneT2.nii.gz: file size mismatch.: 0.00B [00:00‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining11_task-perception_run-06_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining11_task-perception_run-07_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining11_task-perception_run-08_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining12_task-perception_run-02_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining12_task-perception_run-01_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining12_task-perception_run-03_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile()\n",
    "#model.compile(loss=tf.keras.losses.MeanAbsoluteError(), optimizer=tf.keras.optimizers.Adam(), metrics=tf.keras.metrics.Accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b161af7-2a89-471c-82bc-05e16d12a719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining12_task-perception_run-04_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining13_inplaneT2.nii.gz: file size mismatch.: 0.00B [00:00‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining12_task-perception_run-05_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining12_task-perception_run-06_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining12_task-perception_run-07_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining12_task-perception_run-08_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining13_task-perception_run-01_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining13_task-perception_run-02_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining13_task-perception_run-03_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining13_task-perception_run-04_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining14_inplaneT2.nii.gz: file size mismatch.: 0.00B [00:00‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining13_task-perception_run-05_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining13_task-perception_run-06_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining13_task-perception_run-07_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining13_task-perception_run-08_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining14_task-perception_run-01_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining14_task-perception_run-02_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining14_task-perception_run-03_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining14_task-perception_run-04_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining14_task-perception_run-05_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining15_inplaneT2.nii.gz: file size mismatch.: 0.00B [00:00‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining14_task-perception_run-07_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining14_task-perception_run-06_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining14_task-perception_run-08_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining15_task-perception_run-01_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining15_task-perception_run-02_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining15_task-perception_run-04_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining15_task-perception_run-03_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining15_task-perception_run-05_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining15_task-perception_run-06_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining15_task-perception_run-08_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Re-downloading sub-01_ses-perceptionNaturalImageTraining15_task-perception_run-07_bold.nii.gz: file size misma‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ee339-1654-467e-8f96-041cca799710",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5875b8ca-0093-45f5-ab71-5188d6aa938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8a12ef-80ef-49b7-a804-8754815d0bab",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f26ad9a-b173-43bd-b955-257bff8f1924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss, accuracy = model.evaluate(, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d15a09-be64-4d68-bfbb-e49c5a7fe2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
